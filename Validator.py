"""
æ•°æ®é›†éªŒè¯å·¥å…· - Validator
æ£€æŸ¥CSVæ–‡ä»¶å’ŒJSONæ–‡ä»¶æ˜¯å¦ç¬¦åˆSchemaå®šä¹‰ï¼Œä»¥åŠè½¬æ¢æ˜¯å¦æ­£ç¡®

ç‰ˆæœ¬: 1.0.0
"""

import pandas as pd
import json
from pathlib import Path
from typing import Dict, List, Tuple
import sys

class Validator:
    """æ•°æ®é›†éªŒè¯å™¨"""
    
    # è¡¨åæ˜ å°„
    TABLE_MAPPING = {
        "é‡‡ç©ºåŒºåŸºæœ¬ä¿¡æ¯": "goaf_basic_info",
        "é‡‡ç©ºåŒºç§¯æ°´ä¿¡æ¯": "goaf_water_info",
        "é‡‡ç©ºåŒºç§¯æ°”ä¿¡æ¯": "goaf_gas_info",
        "è‡ªç‡ƒå‘ç«ä¿¡æ¯": "fire_info",
        "é‡‡ç©ºåŒºæ‚¬é¡¶ä¿¡æ¯": "suspended_roof_info",
        "é‡‡ç©ºåŒºå¡Œé™·ä¿¡æ¯": "collapse_info",
        "åœ°è£‚ç¼ä¿¡æ¯": "crack_info",
        "åºŸå¼ƒäº•ç­’ä¿¡æ¯": "abandoned_shaft_info",
        "å¯†é—­å¢™ä¿¡æ¯": "seal_wall_info",
        "é‡‡ç©ºåŒºæ²»ç†ä¿¡æ¯": "treatment_info"
    }
    
    def __init__(self, schema_path: str = "ç…¤çŸ¿é‡‡ç©ºåŒºæ™®æŸ¥æ•°æ®é›†Schema.json"):
        """
        åˆå§‹åŒ–éªŒè¯å™¨
        
        Args:
            schema_path: Schemaæ–‡ä»¶è·¯å¾„
        """
        with open(schema_path, 'r', encoding='utf-8') as f:
            self.schema = json.load(f)
        
        # æ„å»ºè¡¨å®šä¹‰å­—å…¸
        self.tables = {table['table_id']: table for table in self.schema['tables']}
        self.table_name_map = {table['table_name']: table for table in self.schema['tables']}
    
    def validate_csv(self, mine_name: str, data_dir: str = ".") -> Dict:
        """
        éªŒè¯CSVæ–‡ä»¶
        
        Args:
            mine_name: ç…¤çŸ¿åç§°
            data_dir: CSVæ–‡ä»¶ç›®å½•
            
        Returns:
            éªŒè¯ç»“æœ
        """
        print(f"\nğŸ“‹ éªŒè¯CSVæ–‡ä»¶: {mine_name}")
        print("=" * 80)
        
        data_path = Path(data_dir)
        results = {
            "mine_name": mine_name,
            "total_tables": 10,
            "found_tables": 0,
            "total_records": 0,
            "errors": [],
            "warnings": [],
            "table_details": {}
        }
        
        for table_cn, table_en in self.TABLE_MAPPING.items():
            file_path = data_path / f"{mine_name}-{table_cn}.csv"
            
            if file_path.exists():
                try:
                    # å°è¯•è¯»å–CSV
                    df = None
                    for encoding in ['utf-8', 'utf-8-sig', 'gbk', 'gb2312']:
                        try:
                            df = pd.read_csv(file_path, encoding=encoding, on_bad_lines='skip')
                            break
                        except:
                            continue
                    
                    if df is None:
                        results["errors"].append(f"{table_cn}: æ— æ³•è¯»å–æ–‡ä»¶")
                        continue
                    
                    results["found_tables"] += 1
                    results["total_records"] += len(df)
                    
                    # è·å–Schemaå®šä¹‰
                    table_schema = self.table_name_map.get(table_cn)
                    if table_schema:
                        # æ£€æŸ¥å­—æ®µ
                        schema_fields = {f['name'] for f in table_schema['fields']}
                        csv_fields = set(df.columns)
                        
                        missing = schema_fields - csv_fields
                        extra = csv_fields - schema_fields
                        
                        if missing:
                            results["warnings"].append(f"{table_cn}: ç¼ºå°‘å­—æ®µ {missing}")
                        if extra:
                            results["warnings"].append(f"{table_cn}: å¤šä½™å­—æ®µ {extra}")
                    
                    results["table_details"][table_cn] = {
                        "records": len(df),
                        "fields": len(df.columns),
                        "status": "âœ…"
                    }
                    
                    print(f"  âœ… {table_cn}: {len(df)}æ¡è®°å½•, {len(df.columns)}ä¸ªå­—æ®µ")
                    
                except Exception as e:
                    results["errors"].append(f"{table_cn}: {str(e)}")
                    print(f"  âŒ {table_cn}: {str(e)}")
            else:
                results["table_details"][table_cn] = {
                    "records": 0,
                    "fields": 0,
                    "status": "âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨"
                }
                print(f"  âš ï¸ {table_cn}: æ–‡ä»¶ä¸å­˜åœ¨")
        
        return results
    
    def validate_json(self, json_path: str) -> Dict:
        """
        éªŒè¯JSONæ–‡ä»¶
        
        Args:
            json_path: JSONæ–‡ä»¶è·¯å¾„
            
        Returns:
            éªŒè¯ç»“æœ
        """
        print(f"\nğŸ“‹ éªŒè¯JSONæ–‡ä»¶: {json_path}")
        print("=" * 80)
        
        results = {
            "file": json_path,
            "valid": True,
            "total_records": 0,
            "errors": [],
            "warnings": [],
            "table_details": {}
        }
        
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æ£€æŸ¥é¡¶å±‚ç»“æ„
            required_keys = ['mine_info', 'statistics', 'data']
            for key in required_keys:
                if key not in data:
                    results["errors"].append(f"ç¼ºå°‘é¡¶å±‚å­—æ®µ: {key}")
                    results["valid"] = False
            
            if not results["valid"]:
                return results
            
            # æ£€æŸ¥æ¯ä¸ªè¡¨
            for table_cn, table_en in self.TABLE_MAPPING.items():
                if table_en in data['data']:
                    records = data['data'][table_en]
                    record_count = len(records)
                    results["total_records"] += record_count
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«NaN
                    json_str = json.dumps(records)
                    if 'NaN' in json_str:
                        results["errors"].append(f"{table_cn}: åŒ…å«NaNå€¼ï¼ˆåº”ä¸ºnullï¼‰")
                    
                    # æ£€æŸ¥ç»Ÿè®¡æ•°æ˜¯å¦ä¸€è‡´
                    if table_en in data['statistics']:
                        stat_count = data['statistics'][table_en]
                        if stat_count != record_count:
                            results["warnings"].append(
                                f"{table_cn}: ç»Ÿè®¡æ•°({stat_count})ä¸å®é™…è®°å½•æ•°({record_count})ä¸ä¸€è‡´"
                            )
                    
                    results["table_details"][table_cn] = {
                        "records": record_count,
                        "status": "âœ…"
                    }
                    
                    print(f"  âœ… {table_cn}: {record_count}æ¡è®°å½•")
                else:
                    results["warnings"].append(f"{table_cn}: è¡¨ä¸å­˜åœ¨")
                    results["table_details"][table_cn] = {
                        "records": 0,
                        "status": "âš ï¸ ä¸å­˜åœ¨"
                    }
                    print(f"  âš ï¸ {table_cn}: è¡¨ä¸å­˜åœ¨")
            
        except Exception as e:
            results["errors"].append(f"è¯»å–JSONå¤±è´¥: {str(e)}")
            results["valid"] = False
            print(f"  âŒ è¯»å–å¤±è´¥: {str(e)}")
        
        return results
    
    def compare_csv_json(self, mine_name: str, json_path: str, csv_dir: str = ".") -> Dict:
        """
        æ¯”å¯¹CSVå’ŒJSONï¼Œæ£€æŸ¥è½¬æ¢æ˜¯å¦æ­£ç¡®
        
        Args:
            mine_name: ç…¤çŸ¿åç§°
            json_path: JSONæ–‡ä»¶è·¯å¾„
            csv_dir: CSVæ–‡ä»¶ç›®å½•
            
        Returns:
            æ¯”å¯¹ç»“æœ
        """
        print(f"\nğŸ” æ¯”å¯¹CSVä¸JSON: {mine_name}")
        print("=" * 80)
        
        results = {
            "mine_name": mine_name,
            "match": True,
            "errors": [],
            "warnings": [],
            "table_comparison": {}
        }
        
        # è¯»å–JSON
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
        except Exception as e:
            results["errors"].append(f"æ— æ³•è¯»å–JSON: {str(e)}")
            results["match"] = False
            return results
        
        # æ¯”å¯¹æ¯ä¸ªè¡¨
        csv_path = Path(csv_dir)
        for table_cn, table_en in self.TABLE_MAPPING.items():
            csv_file = csv_path / f"{mine_name}-{table_cn}.csv"
            
            csv_count = 0
            json_count = 0
            
            # CSVè®°å½•æ•°
            if csv_file.exists():
                try:
                    df = None
                    for encoding in ['utf-8', 'utf-8-sig', 'gbk', 'gb2312']:
                        try:
                            df = pd.read_csv(csv_file, encoding=encoding, on_bad_lines='skip')
                            break
                        except:
                            continue
                    if df is not None:
                        csv_count = len(df)
                except:
                    pass
            
            # JSONè®°å½•æ•°
            if table_en in json_data.get('data', {}):
                json_count = len(json_data['data'][table_en])
            
            # æ¯”å¯¹
            match = (csv_count == json_count)
            if not match:
                results["match"] = False
                results["errors"].append(
                    f"{table_cn}: CSV({csv_count}æ¡) != JSON({json_count}æ¡)"
                )
                status = "âŒ"
            else:
                status = "âœ…"
            
            results["table_comparison"][table_cn] = {
                "csv_records": csv_count,
                "json_records": json_count,
                "match": match,
                "status": status
            }
            
            print(f"  {status} {table_cn}: CSV={csv_count}, JSON={json_count}")
        
        return results
    
    def generate_report(self, csv_result: Dict, json_result: Dict, compare_result: Dict) -> str:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        report = []
        report.append("=" * 80)
        report.append("æ•°æ®é›†éªŒè¯æŠ¥å‘Š")
        report.append("=" * 80)
        report.append("")
        
        # CSVéªŒè¯ç»“æœ
        report.append("ğŸ“‹ CSVæ–‡ä»¶éªŒè¯")
        report.append("-" * 80)
        report.append(f"ç…¤çŸ¿: {csv_result['mine_name']}")
        report.append(f"æ‰¾åˆ°è¡¨: {csv_result['found_tables']}/{csv_result['total_tables']}")
        report.append(f"æ€»è®°å½•æ•°: {csv_result['total_records']}")
        if csv_result['errors']:
            report.append(f"é”™è¯¯: {len(csv_result['errors'])}ä¸ª")
            for error in csv_result['errors']:
                report.append(f"  âŒ {error}")
        if csv_result['warnings']:
            report.append(f"è­¦å‘Š: {len(csv_result['warnings'])}ä¸ª")
            for warning in csv_result['warnings']:
                report.append(f"  âš ï¸ {warning}")
        report.append("")
        
        # JSONéªŒè¯ç»“æœ
        report.append("ğŸ“‹ JSONæ–‡ä»¶éªŒè¯")
        report.append("-" * 80)
        report.append(f"æ–‡ä»¶: {json_result['file']}")
        report.append(f"æœ‰æ•ˆ: {'âœ… æ˜¯' if json_result['valid'] else 'âŒ å¦'}")
        report.append(f"æ€»è®°å½•æ•°: {json_result['total_records']}")
        if json_result['errors']:
            report.append(f"é”™è¯¯: {len(json_result['errors'])}ä¸ª")
            for error in json_result['errors']:
                report.append(f"  âŒ {error}")
        if json_result['warnings']:
            report.append(f"è­¦å‘Š: {len(json_result['warnings'])}ä¸ª")
            for warning in json_result['warnings']:
                report.append(f"  âš ï¸ {warning}")
        report.append("")
        
        # æ¯”å¯¹ç»“æœ
        report.append("ğŸ” CSVä¸JSONæ¯”å¯¹")
        report.append("-" * 80)
        report.append(f"è½¬æ¢æ­£ç¡®: {'âœ… æ˜¯' if compare_result['match'] else 'âŒ å¦'}")
        if compare_result['errors']:
            report.append(f"å·®å¼‚: {len(compare_result['errors'])}ä¸ª")
            for error in compare_result['errors']:
                report.append(f"  âŒ {error}")
        report.append("")
        
        # æ€»ç»“
        report.append("=" * 80)
        all_ok = (
            not csv_result['errors'] and 
            json_result['valid'] and 
            compare_result['match']
        )
        if all_ok:
            report.append("âœ… éªŒè¯é€šè¿‡ï¼CSVå’ŒJSONæ•°æ®ä¸€è‡´ï¼Œè½¬æ¢æ­£ç¡®ã€‚")
        else:
            report.append("âŒ éªŒè¯å¤±è´¥ï¼è¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯å’Œè­¦å‘Šã€‚")
        report.append("=" * 80)
        
        return "\n".join(report)


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•:")
        print("  python Validator.py <ç…¤çŸ¿åç§°>")
        print("  python Validator.py æ²³è¥¿è”åŠç…¤çŸ¿")
        sys.exit(1)
    
    mine_name = sys.argv[1]
    json_file = f"{mine_name}-é‡‡ç©ºåŒºæ•°æ®é›†.json"
    
    # åˆ›å»ºéªŒè¯å™¨
    validator = Validator()
    
    # éªŒè¯CSV
    csv_result = validator.validate_csv(mine_name)
    
    # éªŒè¯JSON
    json_result = validator.validate_json(json_file)
    
    # æ¯”å¯¹CSVå’ŒJSON
    compare_result = validator.compare_csv_json(mine_name, json_file)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = validator.generate_report(csv_result, json_result, compare_result)
    print("\n" + report)
    
    # ä¿å­˜æŠ¥å‘Š
    with open(f"{mine_name}-éªŒè¯æŠ¥å‘Š.txt", 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {mine_name}-éªŒè¯æŠ¥å‘Š.txt")


if __name__ == "__main__":
    main()

